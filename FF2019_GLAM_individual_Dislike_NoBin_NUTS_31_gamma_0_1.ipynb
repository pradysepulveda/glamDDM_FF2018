{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLAM fit. Value based. Gamma parameter limited to 0 - 1 . (Marius Usher recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Individual GLAM estimation prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3327</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.254585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.410720</td>\n",
       "      <td>0.589280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3691</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.330549</td>\n",
       "      <td>0.669451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8144</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.592345</td>\n",
       "      <td>0.407655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6559</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.641717</td>\n",
       "      <td>0.358283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice    rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        0      0       1  3327          0.95          2.00  0.745415   \n",
       "1        0      1       1  3424          2.30          1.70  0.410720   \n",
       "2        0      2       1  3691          1.70          1.25  0.330549   \n",
       "3        0      3       0  8144          1.55          2.30  0.592345   \n",
       "4        0      4       0  6559          2.00          2.00  0.641717   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.254585  \n",
       "1  0.589280  \n",
       "2  0.669451  \n",
       "3  0.407655  \n",
       "4  0.358283  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_individual_Dislike_NoBin_Gamma_01_NUTS_31'\n",
    "data = pd.read_csv('data/FF2018_data/GlamDataFF2018_Dislike_NoBin_31.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1860 trials) and test (1860 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "test_data.to_csv(str('data/FF2018_data/GlamDataFF2019_preprocessed_test'+sufix+'.csv'))\n",
    "train_data.to_csv(str('data/FF2018_data/GlamDataFF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3327</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.254585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3691</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.330549</td>\n",
       "      <td>0.669451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6559</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.641717</td>\n",
       "      <td>0.358283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2470</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.329730</td>\n",
       "      <td>0.670270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4669</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.419431</td>\n",
       "      <td>0.580569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3301</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.605079</td>\n",
       "      <td>0.394921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3117</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.493398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2754</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.596632</td>\n",
       "      <td>0.403368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3931</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.661608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5674</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.589345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2097</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>0.353134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4550</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.558710</td>\n",
       "      <td>0.441290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2824</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.489395</td>\n",
       "      <td>0.510605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2188</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.390219</td>\n",
       "      <td>0.609781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6784</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.530280</td>\n",
       "      <td>0.469720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2952</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.700450</td>\n",
       "      <td>0.299550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5341</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.402985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3207</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.435517</td>\n",
       "      <td>0.564483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3476</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>0.398406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3513</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.595478</td>\n",
       "      <td>0.404522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.438571</td>\n",
       "      <td>0.561429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.343333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3023</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.588341</td>\n",
       "      <td>0.411659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>3961</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.441342</td>\n",
       "      <td>0.558658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1898</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.453097</td>\n",
       "      <td>0.546903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4336</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.514856</td>\n",
       "      <td>0.485144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2479</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.581519</td>\n",
       "      <td>0.418481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.533555</td>\n",
       "      <td>0.466445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>7371</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.573854</td>\n",
       "      <td>0.426146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1761</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.424122</td>\n",
       "      <td>0.575878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3045</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.470937</td>\n",
       "      <td>0.529063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2859</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.508646</td>\n",
       "      <td>0.491354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>6841</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.786435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>5436</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.560588</td>\n",
       "      <td>0.439412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.436293</td>\n",
       "      <td>0.563707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>3020</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.435445</td>\n",
       "      <td>0.564555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1827</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.418172</td>\n",
       "      <td>0.581828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2403</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1522</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.534823</td>\n",
       "      <td>0.465177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.271084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2660</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.620328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>4957</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.423685</td>\n",
       "      <td>0.576315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>30</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>9881</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.497520</td>\n",
       "      <td>0.502480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>30</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>2920</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.488673</td>\n",
       "      <td>0.511327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4725</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.198211</td>\n",
       "      <td>0.801789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2217</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.483240</td>\n",
       "      <td>0.516760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1679</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.362120</td>\n",
       "      <td>0.637880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3311</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.655391</td>\n",
       "      <td>0.344609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1532</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.460836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2287</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.356799</td>\n",
       "      <td>0.643201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>5064</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.397045</td>\n",
       "      <td>0.602955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>3206</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>30</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>3591</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.189362</td>\n",
       "      <td>0.810638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>2241</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.676802</td>\n",
       "      <td>0.323198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>30</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2463</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.629928</td>\n",
       "      <td>0.370072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1538</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.425878</td>\n",
       "      <td>0.574122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>30</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>3410</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.681258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>30</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>3989</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>0.522114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>30</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>10064</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.482076</td>\n",
       "      <td>0.517924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>30</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3853</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.197159</td>\n",
       "      <td>0.802841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1860 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice     rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          0      0       1   3327          0.95          2.00  0.745415   \n",
       "2          0      2       1   3691          1.70          1.25  0.330549   \n",
       "4          0      4       0   6559          2.00          2.00  0.641717   \n",
       "6          0      6       1   2470          1.55          1.10  0.329730   \n",
       "8          0      8       1   4669          1.55          1.70  0.419431   \n",
       "10         0     10       0   3301          1.10          1.10  0.605079   \n",
       "12         0     12       1   3117          1.85          1.10  0.506602   \n",
       "14         0     14       0   2754          1.25          1.55  0.596632   \n",
       "16         0     16       1   3931          1.85          1.70  0.338392   \n",
       "18         0     18       0   5674          1.70          1.40  0.410655   \n",
       "20         0     20       0   2097          1.10          1.55  0.646866   \n",
       "22         0     22       1   4550          1.70          1.55  0.558710   \n",
       "24         0     24       0   2824          1.25          1.70  0.489395   \n",
       "26         0     26       1   2188          1.85          0.65  0.390219   \n",
       "28         0     28       0   6784          1.85          2.00  0.530280   \n",
       "30         0     30       0   2952          1.10          2.00  0.700450   \n",
       "32         0     32       1   5341          1.25          1.85  0.597015   \n",
       "34         0     34       0   3207          0.95          1.85  0.435517   \n",
       "36         0     36       1   3476          1.70          1.85  0.601594   \n",
       "38         0     38       0   3513          1.55          2.30  0.595478   \n",
       "40         0     40       1   2348          1.55          1.10  0.438571   \n",
       "42         0     42       0   1992          1.10          1.70  0.656667   \n",
       "44         0     44       0   3023          0.95          2.30  0.588341   \n",
       "46         0     46       1   3961          2.00          1.55  0.441342   \n",
       "48         0     48       1   1898          2.00          1.10  0.453097   \n",
       "50         0     50       1   4336          2.30          2.00  0.514856   \n",
       "52         0     52       0   2479          0.35          1.85  0.581519   \n",
       "54         0     54       0   2339          1.70          2.00  0.533555   \n",
       "56         0     56       1   7371          2.30          1.55  0.573854   \n",
       "58         0     58       1   1761          2.00          1.40  0.424122   \n",
       "..       ...    ...     ...    ...           ...           ...       ...   \n",
       "60        30     60       1   3045          2.15          0.20  0.470937   \n",
       "62        30     62       1   2859          0.95          0.20  0.508646   \n",
       "64        30     64       0   6841          0.50          0.20  0.213565   \n",
       "66        30     66       1   5436          2.45          0.50  0.560588   \n",
       "68        30     68       1   2072          0.00          0.00  0.436293   \n",
       "70        30     70       1   3020          2.45          3.00  0.435445   \n",
       "72        30     72       1   1827          2.15          0.00  0.418172   \n",
       "74        30     74       1   2403          2.00          0.95  0.239700   \n",
       "76        30     76       1   1522          1.55          1.25  0.534823   \n",
       "78        30     78       0   1978          0.65          2.00  0.728916   \n",
       "80        30     80       1   2660          2.90          1.55  0.379672   \n",
       "82        30     82       0   4957          0.20          0.95  0.423685   \n",
       "84        30     84       1   9881          0.65          2.30  0.497520   \n",
       "86        30     86       0   2920          2.15          2.30  0.488673   \n",
       "88        30     88       1   4725          2.15          3.00  0.198211   \n",
       "90        30     90       1   2217          1.70          2.00  0.483240   \n",
       "92        30     92       1   1679          2.45          0.35  0.362120   \n",
       "94        30     94       0   3311          2.30          0.20  0.655391   \n",
       "96        30     96       0   1532          0.35          0.65  0.539164   \n",
       "98        30     98       1   2287          0.95          0.05  0.356799   \n",
       "100       30    100       1   5064          0.50          0.65  0.397045   \n",
       "102       30    102       1   3206          2.00          2.30  0.362500   \n",
       "104       30    104       1   3591          0.20          0.95  0.189362   \n",
       "106       30    106       0   2241          1.55          2.00  0.676802   \n",
       "108       30    108       0   2463          1.25          1.55  0.629928   \n",
       "110       30    110       1   1538          3.00          0.05  0.425878   \n",
       "112       30    112       1   3410          0.95          2.30  0.318742   \n",
       "114       30    114       1   3989          2.45          2.90  0.477886   \n",
       "116       30    116       0  10064          2.90          0.05  0.482076   \n",
       "118       30    118       1   3853          2.90          2.00  0.197159   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.254585  \n",
       "2    0.669451  \n",
       "4    0.358283  \n",
       "6    0.670270  \n",
       "8    0.580569  \n",
       "10   0.394921  \n",
       "12   0.493398  \n",
       "14   0.403368  \n",
       "16   0.661608  \n",
       "18   0.589345  \n",
       "20   0.353134  \n",
       "22   0.441290  \n",
       "24   0.510605  \n",
       "26   0.609781  \n",
       "28   0.469720  \n",
       "30   0.299550  \n",
       "32   0.402985  \n",
       "34   0.564483  \n",
       "36   0.398406  \n",
       "38   0.404522  \n",
       "40   0.561429  \n",
       "42   0.343333  \n",
       "44   0.411659  \n",
       "46   0.558658  \n",
       "48   0.546903  \n",
       "50   0.485144  \n",
       "52   0.418481  \n",
       "54   0.466445  \n",
       "56   0.426146  \n",
       "58   0.575878  \n",
       "..        ...  \n",
       "60   0.529063  \n",
       "62   0.491354  \n",
       "64   0.786435  \n",
       "66   0.439412  \n",
       "68   0.563707  \n",
       "70   0.564555  \n",
       "72   0.581828  \n",
       "74   0.760300  \n",
       "76   0.465177  \n",
       "78   0.271084  \n",
       "80   0.620328  \n",
       "82   0.576315  \n",
       "84   0.502480  \n",
       "86   0.511327  \n",
       "88   0.801789  \n",
       "90   0.516760  \n",
       "92   0.637880  \n",
       "94   0.344609  \n",
       "96   0.460836  \n",
       "98   0.643201  \n",
       "100  0.602955  \n",
       "102  0.637500  \n",
       "104  0.810638  \n",
       "106  0.323198  \n",
       "108  0.370072  \n",
       "110  0.574122  \n",
       "112  0.681258  \n",
       "114  0.522114  \n",
       "116  0.517924  \n",
       "118  0.802841  \n",
       "\n",
       "[1860 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM individually...\n",
      "Generating single subject models for 31 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '58462' (I am process '58457')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.6.0-x86_64-i386-64bit-i386-3.7.3-64/lock_dir\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 31 model(s) using NUTS...\n",
      "  Fitting model 1 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [12:35<00:00,  5.50draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9678570555295564, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 2 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [11:24<00:00,  4.21draws/s]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8951875632003463, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 3 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [11:29<00:00,  4.08draws/s]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 4 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [23:26<00:00,  2.19draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8934874700448999, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8851442449709996, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 5 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [21:47<00:00,  2.21draws/s]\n",
      "The acceptance probability does not match the target. It is 0.5549574800357339, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9050825302721699, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9830563709430843, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 6 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [03:09<00:00, 63.34draws/s] \n",
      "The acceptance probability does not match the target. It is 0.9409449522034826, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 7 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [02:39<00:00, 75.25draws/s] \n",
      "The acceptance probability does not match the target. It is 0.579809728137012, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9043985634321048, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8815929315022606, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 8 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [04:09<00:00, 48.10draws/s] \n",
      "The acceptance probability does not match the target. It is 0.9663538623718464, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 9 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [28:36<00:00,  1.83draws/s]\n",
      "The acceptance probability does not match the target. It is 0.886383946302345, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9555672357074965, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 10 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:25<00:00, 478.78draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 11 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:20<00:00, 572.19draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 12 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:25<00:00, 477.23draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 13 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [11:55<00:00,  5.68draws/s]\n",
      "The acceptance probability does not match the target. It is 0.965811557447937, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8882666497270206, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 14 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:12<00:00, 967.02draws/s]\n",
      "The acceptance probability does not match the target. It is 0.6920008068824518, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 15 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [11:01<00:00,  4.67draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9779584086243471, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 16 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:38<00:00,  4.46draws/s]\n",
      "The acceptance probability does not match the target. It is 0.6480605074292536, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 17 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:47<00:00,  4.38draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 18 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1255.14draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 19 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [04:55<00:00, 40.57draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9999021340862806, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 20 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:08<00:00, 1405.58draws/s]\n",
      "The acceptance probability does not match the target. It is 0.6958550084711183, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 21 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:11<00:00, 1050.16draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8912668448928877, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 22 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1117.68draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 23 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 470.31draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 24 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1251.51draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9182681257170154, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9005707087309162, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 25 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1129.61draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 26 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:43<00:00,  4.42draws/s]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 27 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:14<00:00, 806.70draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8865077557026498, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9156536992147132, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 28 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:12<00:00, 925.75draws/s]\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 13 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 30 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 29 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:45<00:00,  4.43draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8863200812162527, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.8889009371850716, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9856571054266406, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 30 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:42<00:00,  4.39draws/s]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 31 of 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [01:18<00:00, 153.06draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9022322734837991, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9087966782639275, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_FF2019_full'+sufix+'.npy')):\n",
    "    glam_full.make_model('individual', gamma_bounds=(0, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_FF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR</th>\n",
       "      <th>b</th>\n",
       "      <th>gamma</th>\n",
       "      <th>p_error</th>\n",
       "      <th>s</th>\n",
       "      <th>t0</th>\n",
       "      <th>tau</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>140.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>137.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>139.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>122.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>109.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>206.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>154.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>125.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>199.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>209.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>190.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>162.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>43.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>257.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>330.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>58.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>247.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNR    b  gamma  p_error         s     t0   tau         v\n",
       "0    46.19  1.0   0.19     0.05  0.003239  [0.0]  0.51  0.000059\n",
       "1    37.97  1.0   0.38     0.05  0.004252  [0.0]  0.45  0.000053\n",
       "2    43.56  1.0   0.29     0.05  0.003889  [0.0]  0.01  0.000050\n",
       "3    61.80  1.0   0.15     0.05  0.004826  [0.0]  0.95  0.000078\n",
       "4   181.86  1.0   0.26     0.05  0.011398  [0.0]  1.18  0.000065\n",
       "5   140.20  1.0   0.01     0.05  0.007892  [0.0]  0.01  0.000060\n",
       "6   137.98  1.0   0.01     0.05  0.010018  [0.0]  0.02  0.000063\n",
       "7   139.68  1.0   0.01     0.05  0.007933  [0.0]  0.02  0.000054\n",
       "8    75.03  1.0   0.33     0.05  0.005674  [0.0]  0.42  0.000055\n",
       "9   146.95  1.0   0.01     0.05  0.007912  [0.0]  0.01  0.000071\n",
       "10  122.11  1.0   0.03     0.05  0.006226  [0.0]  0.02  0.000057\n",
       "11  109.82  1.0   0.01     0.05  0.007156  [0.0]  0.01  0.000063\n",
       "12   36.70  1.0   0.30     0.05  0.003009  [0.0]  0.99  0.000063\n",
       "13  206.97  1.0   0.04     0.05  0.010960  [0.0]  0.01  0.000040\n",
       "14   43.68  1.0   0.12     0.05  0.002870  [0.0]  1.41  0.000047\n",
       "15   40.14  1.0   0.30     0.05  0.003666  [0.0]  0.00  0.000060\n",
       "16   40.50  1.0   0.28     0.05  0.003884  [0.0]  0.01  0.000099\n",
       "17  154.24  1.0   0.02     0.05  0.008759  [0.0]  0.01  0.000055\n",
       "18  125.68  1.0   0.07     0.05  0.007249  [0.0]  0.02  0.000058\n",
       "19  128.02  1.0   0.01     0.05  0.007721  [0.0]  1.03  0.000068\n",
       "20  199.59  1.0   0.02     0.05  0.009052  [0.0]  0.01  0.000038\n",
       "21  209.12  1.0   0.01     0.05  0.006796  [0.0]  0.01  0.000030\n",
       "22  100.62  1.0   0.04     0.05  0.009157  [0.0]  0.02  0.000083\n",
       "23  190.12  1.0   0.02     0.05  0.008045  [0.0]  0.48  0.000038\n",
       "24  162.18  1.0   0.02     0.05  0.009576  [0.0]  0.01  0.000049\n",
       "25   43.26  1.0   0.37     0.05  0.004801  [0.0]  0.05  0.000103\n",
       "26  257.43  1.0   0.01     0.05  0.009864  [0.0]  0.54  0.000028\n",
       "27   55.85  1.0   0.01     0.05  0.006620  [0.0]  0.01  0.000098\n",
       "28  330.34  1.0   0.23     0.05  0.008573  [0.0]  1.64  0.000052\n",
       "29   58.17  1.0   0.33     0.05  0.004447  [0.0]  0.62  0.000044\n",
       "30  247.16  1.0   0.01     0.05  0.008916  [0.0]  0.01  0.000031"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_FF2019_full'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_params = pd.DataFrame(glam_full.estimates)\n",
    "full_params.to_csv(str('results/params_estimates/params_glam_FF2019_full'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:168: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.stack(logp)\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/pymc3/stats.py:219: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_FF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_FF2019_full'+ sufix +'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_FF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_values = pd.DataFrame(glam_full.waic)\n",
    "waic_values.to_csv(str('results/params_estimates/waic_estimate'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.67510587e+03, 0.00000000e+00, 1.27991643e+03, 1.00000000e+00],\n",
       "       [1.77681731e+03, 0.00000000e+00, 3.40834640e+02, 1.00000000e+00],\n",
       "       [1.16924109e+04, 0.00000000e+00, 5.29046438e+03, 1.00000000e+00],\n",
       "       [2.79896568e+03, 0.00000000e+00, 8.28909984e+02, 1.00000000e+00],\n",
       "       [1.56496455e+03, 0.00000000e+00, 2.26515317e+02, 1.00000000e+00],\n",
       "       [1.09649556e+03, 0.00000000e+00, 1.96003589e+00, 1.00000000e+00],\n",
       "       [1.08702611e+03, 0.00000000e+00, 1.95131486e+00, 1.00000000e+00],\n",
       "       [1.08408026e+03, 0.00000000e+00, 2.25676056e+00, 1.00000000e+00],\n",
       "       [1.11406139e+03, 0.00000000e+00, 1.94196570e+01, 1.00000000e+00],\n",
       "       [1.08374098e+03, 0.00000000e+00, 1.99816935e+00, 1.00000000e+00],\n",
       "       [1.06649756e+03, 0.00000000e+00, 1.83220820e+00, 1.00000000e+00],\n",
       "       [1.07397658e+03, 0.00000000e+00, 1.96972366e+00, 1.00000000e+00],\n",
       "       [3.80984391e+03, 0.00000000e+00, 1.36193168e+03, 1.00000000e+00],\n",
       "       [1.14350604e+03, 0.00000000e+00, 1.90753859e+00, 1.00000000e+00],\n",
       "       [7.13380680e+03, 0.00000000e+00, 3.00669437e+03, 1.00000000e+00],\n",
       "       [1.23462733e+03, 0.00000000e+00, 7.93918170e+01, 1.00000000e+00],\n",
       "       [2.99718534e+03, 0.00000000e+00, 9.76722789e+02, 1.00000000e+00],\n",
       "       [1.09889729e+03, 0.00000000e+00, 2.09866278e+00, 1.00000000e+00],\n",
       "       [1.07731365e+03, 0.00000000e+00, 1.70991836e+00, 1.00000000e+00],\n",
       "       [1.04909335e+03, 0.00000000e+00, 2.89444425e+00, 1.00000000e+00],\n",
       "       [1.14948752e+03, 0.00000000e+00, 2.00795395e+00, 1.00000000e+00],\n",
       "       [1.16114955e+03, 0.00000000e+00, 1.94472141e+00, 1.00000000e+00],\n",
       "       [1.04716834e+03, 0.00000000e+00, 2.10880623e+00, 1.00000000e+00],\n",
       "       [1.13221944e+03, 0.00000000e+00, 2.48224722e+00, 1.00000000e+00],\n",
       "       [1.13534754e+03, 0.00000000e+00, 2.46755598e+00, 1.00000000e+00],\n",
       "       [1.38127635e+03, 0.00000000e+00, 1.14857788e+02, 1.00000000e+00],\n",
       "       [1.17866626e+03, 0.00000000e+00, 1.97845741e+00, 1.00000000e+00],\n",
       "       [1.02849987e+03, 0.00000000e+00, 2.05061589e+00, 1.00000000e+00],\n",
       "       [2.76490223e+03, 0.00000000e+00, 7.78723080e+02, 1.00000000e+00],\n",
       "       [1.43610955e+03, 0.00000000e+00, 1.66936071e+02, 1.00000000e+00],\n",
       "       [1.17232078e+03, 0.00000000e+00, 1.84124066e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'nchains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9c5bab22402f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute LOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/loo/glam_FF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msufix\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats.py\u001b[0m in \u001b[0;36mloo\u001b[0;34m(trace, model, pointwise, reff, progressbar)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreff\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnchains\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mreff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'nchains'"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_FF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'loo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-12528b9778fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'loo'"
     ]
    }
   ],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set data using full GLAM...\n",
      "Replaced attached data (1860 trials) with new data (1860 trials)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>repeat</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3405.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.41072</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.58928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.41072</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.58928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2816.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.41072</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.58928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.41072</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.58928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.41072</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.58928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  repeat  choice      rt  item_value_0   gaze_0  \\\n",
       "0      0.0    0.0     0.0     1.0  3405.0           2.3  0.41072   \n",
       "1      0.0    0.0     1.0     1.0  3291.0           2.3  0.41072   \n",
       "2      0.0    0.0     2.0     0.0  2816.0           2.3  0.41072   \n",
       "3      0.0    0.0     3.0     0.0  2832.0           2.3  0.41072   \n",
       "4      0.0    0.0     4.0     0.0  3003.0           2.3  0.41072   \n",
       "\n",
       "   item_value_1   gaze_1  \n",
       "0           1.7  0.58928  \n",
       "1           1.7  0.58928  \n",
       "2           1.7  0.58928  \n",
       "3           1.7  0.58928  \n",
       "4           1.7  0.58928  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_FF2019_full'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_FF2019_full'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_FF2019_full'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "glam.plots_pretty.plot_fit(test_data, [glam_full.prediction]);\n",
    "\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
