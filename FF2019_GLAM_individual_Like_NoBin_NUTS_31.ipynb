{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Individual GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.568396</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3371</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7466</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.532352</td>\n",
       "      <td>0.467648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1889</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.529736</td>\n",
       "      <td>0.470264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice    rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        0      0       0  2009          1.10          0.95  0.568396   \n",
       "1        0      1       0  3371          2.00          1.70  0.762332   \n",
       "2        0      2       1  1700          1.10          2.30  0.446809   \n",
       "3        0      3       1  7466          1.25          1.40  0.532352   \n",
       "4        0      4       1  1889          2.00          2.30  0.529736   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.431604  \n",
       "1  0.237668  \n",
       "2  0.553191  \n",
       "3  0.467648  \n",
       "4  0.470264  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_individual_Like_NoBin_Gamma-11_NUTS_31'\n",
    "\n",
    "data = pd.read_csv('data/FF2018_data/GlamDataFF2018_Like_NoBin_31.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1860 trials) and test (1860 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "test_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_test'+sufix+'.csv'))\n",
    "train_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.568396</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1889</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.529736</td>\n",
       "      <td>0.470264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4259</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.482254</td>\n",
       "      <td>0.517746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2548</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.471503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4604</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.537755</td>\n",
       "      <td>0.462245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5716</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.584666</td>\n",
       "      <td>0.415334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2447</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.413978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6932</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.585313</td>\n",
       "      <td>0.414687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6854</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.591492</td>\n",
       "      <td>0.408508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2913</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.553136</td>\n",
       "      <td>0.446864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.373274</td>\n",
       "      <td>0.626726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2456</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.343508</td>\n",
       "      <td>0.656492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>7010</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.472888</td>\n",
       "      <td>0.527112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2697</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.367032</td>\n",
       "      <td>0.632968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1916</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.407251</td>\n",
       "      <td>0.592749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1441</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>0.538206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>7377</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.601685</td>\n",
       "      <td>0.398315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6398</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.594283</td>\n",
       "      <td>0.405717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4737</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.549409</td>\n",
       "      <td>0.450591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3454</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.411979</td>\n",
       "      <td>0.588021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1728</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.348914</td>\n",
       "      <td>0.651086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>3216</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.490013</td>\n",
       "      <td>0.509987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1467</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.573906</td>\n",
       "      <td>0.426094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1472</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.385870</td>\n",
       "      <td>0.614130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5621</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.476261</td>\n",
       "      <td>0.523739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3167</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.434337</td>\n",
       "      <td>0.565663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2066</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.571274</td>\n",
       "      <td>0.428726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2037</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2752</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.566104</td>\n",
       "      <td>0.433896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1675</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.475821</td>\n",
       "      <td>0.524179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1641</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.380135</td>\n",
       "      <td>0.619865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3286</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.384766</td>\n",
       "      <td>0.615234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>4459</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.435933</td>\n",
       "      <td>0.564067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6405</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.405985</td>\n",
       "      <td>0.594015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>4429</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.710544</td>\n",
       "      <td>0.289456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2278</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.561896</td>\n",
       "      <td>0.438104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2534</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.391683</td>\n",
       "      <td>0.608317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4478</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.443876</td>\n",
       "      <td>0.556124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>9789</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.274873</td>\n",
       "      <td>0.725127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4597</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.388732</td>\n",
       "      <td>0.611268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>30</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>3562</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.250142</td>\n",
       "      <td>0.749858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>30</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1884</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.615711</td>\n",
       "      <td>0.384289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2179</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.453704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>2713</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.468116</td>\n",
       "      <td>0.531884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>2694</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.501209</td>\n",
       "      <td>0.498791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2285</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.465208</td>\n",
       "      <td>0.534792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>2841</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.308342</td>\n",
       "      <td>0.691658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.576364</td>\n",
       "      <td>0.423636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2423</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.487979</td>\n",
       "      <td>0.512021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>3420</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.547953</td>\n",
       "      <td>0.452047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>30</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>5417</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.573380</td>\n",
       "      <td>0.426620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1789</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.667442</td>\n",
       "      <td>0.332558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>30</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3252</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.401150</td>\n",
       "      <td>0.598850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.522402</td>\n",
       "      <td>0.477598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>30</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>3779</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.381847</td>\n",
       "      <td>0.618153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>30</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2133</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.379747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>30</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>1213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.589121</td>\n",
       "      <td>0.410879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>30</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>5280</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.382619</td>\n",
       "      <td>0.617381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1860 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice    rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          0      0       0  2009          1.10          0.95  0.568396   \n",
       "2          0      2       1  1700          1.10          2.30  0.446809   \n",
       "4          0      4       1  1889          2.00          2.30  0.529736   \n",
       "6          0      6       0  4259          1.85          0.65  0.482254   \n",
       "8          0      8       0  2548          1.55          1.10  0.528497   \n",
       "10         0     10       0  4604          1.85          1.10  0.537755   \n",
       "12         0     12       0  5716          0.95          0.80  0.584666   \n",
       "14         0     14       0  2447          1.85          1.10  0.586022   \n",
       "16         0     16       1  6932          2.00          2.00  0.585313   \n",
       "18         0     18       0  6854          1.70          1.40  0.591492   \n",
       "20         0     20       0  2913          1.10          0.95  0.553136   \n",
       "22         0     22       1  2110          1.85          2.00  0.373274   \n",
       "24         0     24       1  2456          1.40          2.00  0.343508   \n",
       "26         0     26       1  7010          1.10          1.55  0.472888   \n",
       "28         0     28       1  2697          1.10          1.55  0.367032   \n",
       "30         0     30       1  1916          1.55          2.30  0.407251   \n",
       "32         0     32       1  1441          0.95          1.85  0.461794   \n",
       "34         0     34       1  7377          1.70          2.00  0.601685   \n",
       "36         0     36       0  6398          1.55          2.30  0.594283   \n",
       "38         0     38       0  4737          1.55          1.70  0.549409   \n",
       "40         0     40       1  3454          1.85          1.85  0.411979   \n",
       "42         0     42       1  1728          1.10          1.85  0.348914   \n",
       "44         0     44       1   519          0.95          1.10  1.000000   \n",
       "46         0     46       1  3216          1.10          1.70  0.490013   \n",
       "48         0     48       0  1467          2.30          2.00  0.573906   \n",
       "50         0     50       1  1472          1.10          1.55  0.385870   \n",
       "52         0     52       1  5621          2.30          1.55  0.476261   \n",
       "54         0     54       1  3167          0.95          2.30  0.434337   \n",
       "56         0     56       0  2066          1.55          1.40  0.571274   \n",
       "58         0     58       0  2037          1.85          1.55  0.617021   \n",
       "..       ...    ...     ...   ...           ...           ...       ...   \n",
       "60        30     60       0  2752          2.00          0.95  0.566104   \n",
       "62        30     62       0  1675          2.30          0.00  0.475821   \n",
       "64        30     64       1  1641          0.35          2.45  0.380135   \n",
       "66        30     66       0  3286          1.55          0.00  0.384766   \n",
       "68        30     68       0  4459          1.70          2.45  0.435933   \n",
       "70        30     70       0  6405          0.65          2.00  0.405985   \n",
       "72        30     72       0  4429          2.45          3.00  0.710544   \n",
       "74        30     74       0  2278          2.15          0.00  0.561896   \n",
       "76        30     76       0  2534          3.00          2.00  0.391683   \n",
       "78        30     78       1  4478          2.00          2.90  0.443876   \n",
       "80        30     80       0  9789          2.00          0.00  0.274873   \n",
       "82        30     82       1  4597          2.30          0.20  0.388732   \n",
       "84        30     84       1  3562          2.15          0.65  0.250142   \n",
       "86        30     86       0  1884          2.45          0.35  0.615711   \n",
       "88        30     88       0  2179          2.90          1.55  0.546296   \n",
       "90        30     90       0  2713          2.15          3.00  0.468116   \n",
       "92        30     92       0  2694          2.00          2.30  0.501209   \n",
       "94        30     94       1  2285          2.00          0.50  0.465208   \n",
       "96        30     96       1  2841          0.20          0.95  0.308342   \n",
       "98        30     98       1  1243          0.00          2.60  0.576364   \n",
       "100       30    100       1  2423          3.00          1.10  0.487979   \n",
       "102       30    102       1  3420          2.90          2.00  0.547953   \n",
       "104       30    104       1  5417          2.45          2.90  0.573380   \n",
       "106       30    106       0  1789          3.00          0.05  0.667442   \n",
       "108       30    108       1  3252          2.00          2.15  0.401150   \n",
       "110       30    110       0  2098          0.20          0.95  0.522402   \n",
       "112       30    112       0  3779          1.25          1.55  0.381847   \n",
       "114       30    114       0  2133          0.50          0.65  0.620253   \n",
       "116       30    116       1  1213          0.00          2.30  0.589121   \n",
       "118       30    118       1  5280          2.45          2.45  0.382619   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.431604  \n",
       "2    0.553191  \n",
       "4    0.470264  \n",
       "6    0.517746  \n",
       "8    0.471503  \n",
       "10   0.462245  \n",
       "12   0.415334  \n",
       "14   0.413978  \n",
       "16   0.414687  \n",
       "18   0.408508  \n",
       "20   0.446864  \n",
       "22   0.626726  \n",
       "24   0.656492  \n",
       "26   0.527112  \n",
       "28   0.632968  \n",
       "30   0.592749  \n",
       "32   0.538206  \n",
       "34   0.398315  \n",
       "36   0.405717  \n",
       "38   0.450591  \n",
       "40   0.588021  \n",
       "42   0.651086  \n",
       "44   0.000000  \n",
       "46   0.509987  \n",
       "48   0.426094  \n",
       "50   0.614130  \n",
       "52   0.523739  \n",
       "54   0.565663  \n",
       "56   0.428726  \n",
       "58   0.382979  \n",
       "..        ...  \n",
       "60   0.433896  \n",
       "62   0.524179  \n",
       "64   0.619865  \n",
       "66   0.615234  \n",
       "68   0.564067  \n",
       "70   0.594015  \n",
       "72   0.289456  \n",
       "74   0.438104  \n",
       "76   0.608317  \n",
       "78   0.556124  \n",
       "80   0.725127  \n",
       "82   0.611268  \n",
       "84   0.749858  \n",
       "86   0.384289  \n",
       "88   0.453704  \n",
       "90   0.531884  \n",
       "92   0.498791  \n",
       "94   0.534792  \n",
       "96   0.691658  \n",
       "98   0.423636  \n",
       "100  0.512021  \n",
       "102  0.452047  \n",
       "104  0.426620  \n",
       "106  0.332558  \n",
       "108  0.598850  \n",
       "110  0.477598  \n",
       "112  0.618153  \n",
       "114  0.379747  \n",
       "116  0.410879  \n",
       "118  0.617381  \n",
       "\n",
       "[1860 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM individually...\n",
      "Generating single subject models for 31 subjects...\n",
      "\n",
      "You can find the C code in this temporary file: /var/folders/np/3gkzqfkd6vddg92v1ytvrkkc0000gn/T/theano_compilation_error_dn8_2dbv\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(\"Compilation failed (return status=1): In file included from /Users/pradyumna/.theano/compiledir_Darwin-18.2.0-x86_64-i386-64bit-i386-3.5.4-64/tmpcwkhdort/mod.cpp:1:. In file included from /Users/pradyumna/anaconda/include/python3.5m/Python.h:25:. /Users/pradyumna/anaconda/bin/../include/c++/v1/stdio.h:108:15: fatal error: 'stdio.h' file not found. #include_next <stdio.h>.               ^~~~~~~~~. 1 error generated.. \", '[Elemwise{add,no_inplace}(TensorConstant{0.01}, TensorConstant{1e-06})]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2aa532b553cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/estimates/glam_FF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'individual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NUTS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_FF2018/glam/models.py\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(self, kind, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_FF2018/glam/models.py\u001b[0m in \u001b[0;36mmake_models\u001b[0;34m(df, kind, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m                                                \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_idx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                                \u001b[0merror_ll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error_lls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_FF2018/glam/models.py\u001b[0m in \u001b[0;36mmake_subject_model\u001b[0;34m(rts, gaze, values, error_ll, v_val, gamma_val, s_val, tau_val, t0_val, zerotol, error_weight, boundary, gamma_bounds)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Parameter priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzerotol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeterministic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/pymc3/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"observed needs to be data but got: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/pymc3/distributions/distribution.py\u001b[0m in \u001b[0;36mdist\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/pymc3/distributions/continuous.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lower, upper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;31m# We should catch the minimum number of exception here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Otherwise this will convert error when Theano flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;31m# compute output value once with test inputs to validate graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 thunk = node.op.make_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 670\u001b[0;31m                                            no_recycling=[])\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 955\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 858\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                             \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         return (thunk,\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1618\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1620\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1521\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1524\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2386\u001b[0m             \u001b[0;31m# difficult to read.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m             raise Exception('Compilation failed (return status=%s): %s' %\n\u001b[0;32m-> 2388\u001b[0;31m                             (status, compile_stderr.replace('\\n', '. ')))\n\u001b[0m\u001b[1;32m   2389\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m             \u001b[0;31m# Print errors just below the command line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (\"Compilation failed (return status=1): In file included from /Users/pradyumna/.theano/compiledir_Darwin-18.2.0-x86_64-i386-64bit-i386-3.5.4-64/tmpcwkhdort/mod.cpp:1:. In file included from /Users/pradyumna/anaconda/include/python3.5m/Python.h:25:. /Users/pradyumna/anaconda/bin/../include/c++/v1/stdio.h:108:15: fatal error: 'stdio.h' file not found. #include_next <stdio.h>.               ^~~~~~~~~. 1 error generated.. \", '[Elemwise{add,no_inplace}(TensorConstant{0.01}, TensorConstant{1e-06})]')"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_FF2019_full'+sufix+'.npy')):\n",
    "    glam_full.make_model('individual', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_FF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_FF2019_full'+sufix+'.npy'), glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_FF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_FF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_FF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_FF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_FF2019_full'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_FF2019_full'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_FF2019_full'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM individually...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_FF2019_nobias'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_FF2019_nobias'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_FF2019_nobias'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_FF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
