{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Hierarchical GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_Like_NoBin_NUTS_31_eLife'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.568396</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3371</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7466</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.532352</td>\n",
       "      <td>0.467648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1889</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.529736</td>\n",
       "      <td>0.470264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice    rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        0      0       0  2009          1.10          0.95  0.568396   \n",
       "1        0      1       0  3371          2.00          1.70  0.762332   \n",
       "2        0      2       1  1700          1.10          2.30  0.446809   \n",
       "3        0      3       1  7466          1.25          1.40  0.532352   \n",
       "4        0      4       1  1889          2.00          2.30  0.529736   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.431604  \n",
       "1  0.237668  \n",
       "2  0.553191  \n",
       "3  0.467648  \n",
       "4  0.470264  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/FF2018_data/GlamDataFF2018_Like_NoBin_31.csv')\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.subject.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1860 trials) and test (1860 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "test_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_test'+sufix+'.csv'))\n",
    "train_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 31 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 11:20<00:00 Sampling 4 chains, 16 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 683 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 7 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>159.65</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>154.10</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>155.24</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>161.17</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.008030</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.15</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>127.89</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>145.75</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>159.44</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>174.47</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>163.16</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>148.12</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>138.37</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>161.88</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>185.28</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.48</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>163.59</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>142.73</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>135.58</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>100.83</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>113.66</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>184.82</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>188.79</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>110.98</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>181.25</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.03</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>216.21</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>147.26</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>129.84</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>176.77</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>178.03</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>169.79</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>161.21</td>\n",
       "      <td>34.57</td>\n",
       "      <td>173.45</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error      v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.000053  0.000013  0.000046     -0.23      0.39   0.01   \n",
       "1   1.0     0.05  0.000053  0.000013  0.000073     -0.23      0.39   0.40   \n",
       "2   1.0     0.05  0.000053  0.000013  0.000056     -0.23      0.39   0.00   \n",
       "3   1.0     0.05  0.000053  0.000013  0.000043     -0.23      0.39  -0.10   \n",
       "4   1.0     0.05  0.000053  0.000013  0.000079     -0.23      0.39  -0.41   \n",
       "5   1.0     0.05  0.000053  0.000013  0.000060     -0.23      0.39   0.15   \n",
       "6   1.0     0.05  0.000053  0.000013  0.000067     -0.23      0.39  -0.03   \n",
       "7   1.0     0.05  0.000053  0.000013  0.000044     -0.23      0.39  -0.01   \n",
       "8   1.0     0.05  0.000053  0.000013  0.000053     -0.23      0.39  -0.87   \n",
       "9   1.0     0.05  0.000053  0.000013  0.000047     -0.23      0.39  -0.04   \n",
       "10  1.0     0.05  0.000053  0.000013  0.000046     -0.23      0.39  -0.09   \n",
       "11  1.0     0.05  0.000053  0.000013  0.000050     -0.23      0.39  -0.25   \n",
       "12  1.0     0.05  0.000053  0.000013  0.000045     -0.23      0.39  -0.04   \n",
       "13  1.0     0.05  0.000053  0.000013  0.000044     -0.23      0.39   0.12   \n",
       "14  1.0     0.05  0.000053  0.000013  0.000045     -0.23      0.39   0.48   \n",
       "15  1.0     0.05  0.000053  0.000013  0.000051     -0.23      0.39  -0.61   \n",
       "16  1.0     0.05  0.000053  0.000013  0.000056     -0.23      0.39   0.01   \n",
       "17  1.0     0.05  0.000053  0.000013  0.000054     -0.23      0.39  -0.34   \n",
       "18  1.0     0.05  0.000053  0.000013  0.000059     -0.23      0.39  -0.71   \n",
       "19  1.0     0.05  0.000053  0.000013  0.000073     -0.23      0.39  -0.70   \n",
       "20  1.0     0.05  0.000053  0.000013  0.000046     -0.23      0.39  -0.38   \n",
       "21  1.0     0.05  0.000053  0.000013  0.000035     -0.23      0.39  -0.20   \n",
       "22  1.0     0.05  0.000053  0.000013  0.000079     -0.23      0.39  -0.14   \n",
       "23  1.0     0.05  0.000053  0.000013  0.000043     -0.23      0.39  -0.40   \n",
       "24  1.0     0.05  0.000053  0.000013  0.000033     -0.23      0.39   0.03   \n",
       "25  1.0     0.05  0.000053  0.000013  0.000053     -0.23      0.39  -0.15   \n",
       "26  1.0     0.05  0.000053  0.000013  0.000054     -0.23      0.39  -0.81   \n",
       "27  1.0     0.05  0.000053  0.000013  0.000056     -0.23      0.39  -0.28   \n",
       "28  1.0     0.05  0.000053  0.000013  0.000034     -0.23      0.39  -0.67   \n",
       "29  1.0     0.05  0.000053  0.000013  0.000045     -0.23      0.39  -0.61   \n",
       "30  1.0     0.05  0.000053  0.000013  0.000042     -0.23      0.39  -0.33   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   161.21   34.57  159.65  0.007942    3.31    1.12  3.71  0.0  \n",
       "1   161.21   34.57  154.10  0.010285    3.31    1.12  4.52  0.0  \n",
       "2   161.21   34.57  155.24  0.008448    3.31    1.12  3.46  0.0  \n",
       "3   161.21   34.57  161.17  0.007056    3.31    1.12  4.30  0.0  \n",
       "4   161.21   34.57   91.63  0.008030    3.31    1.12  3.96  0.0  \n",
       "5   161.21   34.57  127.89  0.007702    3.31    1.12  2.21  0.0  \n",
       "6   161.21   34.57  145.75  0.010172    3.31    1.12  3.37  0.0  \n",
       "7   161.21   34.57  159.44  0.006929    3.31    1.12  2.97  0.0  \n",
       "8   161.21   34.57  174.47  0.009043    3.31    1.12  1.49  0.0  \n",
       "9   161.21   34.57  163.16  0.007938    3.31    1.12  4.56  0.0  \n",
       "10  161.21   34.57  148.12  0.007168    3.31    1.12  2.12  0.0  \n",
       "11  161.21   34.57  138.37  0.007187    3.31    1.12  2.54  0.0  \n",
       "12  161.21   34.57  161.88  0.007963    3.31    1.12  3.84  0.0  \n",
       "13  161.21   34.57  185.28  0.008034    3.31    1.12  2.68  0.0  \n",
       "14  161.21   34.57  163.59  0.007804    3.31    1.12  3.21  0.0  \n",
       "15  161.21   34.57  142.73  0.007600    3.31    1.12  4.48  0.0  \n",
       "16  161.21   34.57  135.58  0.008351    3.31    1.12  4.72  0.0  \n",
       "17  161.21   34.57  100.83  0.006110    3.31    1.12  4.01  0.0  \n",
       "18  161.21   34.57  113.66  0.007443    3.31    1.12  3.04  0.0  \n",
       "19  161.21   34.57   77.91  0.006120    3.31    1.12  4.12  0.0  \n",
       "20  161.21   34.57  184.82  0.007948    3.31    1.12  3.20  0.0  \n",
       "21  161.21   34.57  188.79  0.007009    3.31    1.12  1.08  0.0  \n",
       "22  161.21   34.57  110.98  0.008638    3.31    1.12  4.68  0.0  \n",
       "23  161.21   34.57  181.25  0.007465    3.31    1.12  4.25  0.0  \n",
       "24  161.21   34.57  216.21  0.007555    3.31    1.12  4.30  0.0  \n",
       "25  161.21   34.57  147.26  0.008534    3.31    1.12  2.65  0.0  \n",
       "26  161.21   34.57  129.84  0.007730    3.31    1.12  3.74  0.0  \n",
       "27  161.21   34.57  176.77  0.010337    3.31    1.12  3.76  0.0  \n",
       "28  161.21   34.57  178.03  0.006900    3.31    1.12  2.83  0.0  \n",
       "29  161.21   34.57  169.79  0.007486    3.31    1.12  4.12  0.0  \n",
       "30  161.21   34.57  173.45  0.008182    3.31    1.12  0.58  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_FF2018_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_FF2018_full_hierarchical_cv'+sufix+'.npy'))   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_FF2018_full_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>-0.000969</td>\n",
       "      <td>-0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000908</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.001553</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.001549</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.001110</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.001308</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.000711</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.000410</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.002416</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.001462</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>-0.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.000825</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>-0.000397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0  -0.000889  0.000219 -0.000314 -0.000107\n",
       "1  -0.000524 -0.000561 -0.000969 -0.000664\n",
       "2  -0.000925 -0.000091  0.000049  0.000208\n",
       "3  -0.000908  0.000100 -0.000539 -0.000232\n",
       "4  -0.000226 -0.001592 -0.001061 -0.001254\n",
       "5  -0.000404 -0.000736 -0.000456 -0.000367\n",
       "6  -0.001553 -0.000160 -0.001411 -0.000530\n",
       "7  -0.000208 -0.000821  0.000129  0.000033\n",
       "8  -0.001161  0.000104  0.000205  0.000231\n",
       "9  -0.000708 -0.000363 -0.000095 -0.001082\n",
       "10 -0.001549 -0.000781 -0.000539 -0.000346\n",
       "11 -0.000579 -0.001110 -0.000787 -0.001009\n",
       "12 -0.001308 -0.000441 -0.000335 -0.000403\n",
       "13 -0.000711  0.000263 -0.000369 -0.000032\n",
       "14 -0.000435 -0.001336 -0.000299  0.000027\n",
       "15 -0.000453 -0.001602 -0.000203 -0.000962\n",
       "16 -0.000410 -0.000754 -0.000003 -0.001032\n",
       "17 -0.002416 -0.001029  0.000298 -0.000025\n",
       "18 -0.000285  0.000007  0.000296  0.000027\n",
       "19 -0.001129 -0.001462 -0.000365 -0.000222\n",
       "20 -0.001042 -0.000026 -0.000207 -0.000724\n",
       "21 -0.001702 -0.000726 -0.000630 -0.000740\n",
       "22 -0.000197 -0.000548 -0.000448  0.000086\n",
       "23 -0.001384 -0.000271 -0.000924 -0.000015\n",
       "24 -0.000167  0.000061 -0.002337  0.000272\n",
       "25 -0.000333 -0.000496 -0.001411  0.000052\n",
       "26  0.000009 -0.000935 -0.000052 -0.000254\n",
       "27 -0.000275 -0.000557 -0.000795 -0.001039\n",
       "28 -0.000047 -0.000845 -0.000531 -0.000313\n",
       "29 -0.000791 -0.000671  0.000092 -0.001260\n",
       "30 -0.000825 -0.000259 -0.000569 -0.000397"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8884.732608</td>\n",
       "      <td>5092.459921</td>\n",
       "      <td>4542.970058</td>\n",
       "      <td>6707.750088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4704.557958</td>\n",
       "      <td>5203.909878</td>\n",
       "      <td>5159.123768</td>\n",
       "      <td>7375.008337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5217.056885</td>\n",
       "      <td>5508.815879</td>\n",
       "      <td>4920.184063</td>\n",
       "      <td>7225.073549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7011.748107</td>\n",
       "      <td>5988.528729</td>\n",
       "      <td>5294.835363</td>\n",
       "      <td>8611.396447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6035.102977</td>\n",
       "      <td>4393.755200</td>\n",
       "      <td>4749.595096</td>\n",
       "      <td>6736.258010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8677.182441</td>\n",
       "      <td>4251.019052</td>\n",
       "      <td>4336.435955</td>\n",
       "      <td>6421.818550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7369.234961</td>\n",
       "      <td>4864.578853</td>\n",
       "      <td>5164.778288</td>\n",
       "      <td>6552.589846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7334.908527</td>\n",
       "      <td>4190.840833</td>\n",
       "      <td>4172.384118</td>\n",
       "      <td>6528.635877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6030.395855</td>\n",
       "      <td>4141.106323</td>\n",
       "      <td>4473.043016</td>\n",
       "      <td>5296.626783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8099.383958</td>\n",
       "      <td>5314.817037</td>\n",
       "      <td>5415.240393</td>\n",
       "      <td>6434.156664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7244.654160</td>\n",
       "      <td>3632.125448</td>\n",
       "      <td>3374.219857</td>\n",
       "      <td>5889.242901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6556.733510</td>\n",
       "      <td>4288.296396</td>\n",
       "      <td>4868.352670</td>\n",
       "      <td>7486.754945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7477.498633</td>\n",
       "      <td>5665.777880</td>\n",
       "      <td>5440.708012</td>\n",
       "      <td>7546.222567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7170.113679</td>\n",
       "      <td>4191.561947</td>\n",
       "      <td>4367.144170</td>\n",
       "      <td>7163.378770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6485.407376</td>\n",
       "      <td>3717.380929</td>\n",
       "      <td>3882.242308</td>\n",
       "      <td>6775.033931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6425.877406</td>\n",
       "      <td>4660.450008</td>\n",
       "      <td>4707.634304</td>\n",
       "      <td>6721.199446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6185.433614</td>\n",
       "      <td>5271.489492</td>\n",
       "      <td>5654.610884</td>\n",
       "      <td>6828.246178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8894.067953</td>\n",
       "      <td>5356.878475</td>\n",
       "      <td>5117.243664</td>\n",
       "      <td>7430.084047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5250.676408</td>\n",
       "      <td>4487.761192</td>\n",
       "      <td>4419.580821</td>\n",
       "      <td>6799.648448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3015.906157</td>\n",
       "      <td>2919.125506</td>\n",
       "      <td>3131.643094</td>\n",
       "      <td>4268.952393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4972.372561</td>\n",
       "      <td>4762.635583</td>\n",
       "      <td>5464.755507</td>\n",
       "      <td>6646.304055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5278.034575</td>\n",
       "      <td>3950.053569</td>\n",
       "      <td>4071.672884</td>\n",
       "      <td>4820.922179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7743.988474</td>\n",
       "      <td>4114.612787</td>\n",
       "      <td>3875.449768</td>\n",
       "      <td>6123.320301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6231.467890</td>\n",
       "      <td>5041.165349</td>\n",
       "      <td>6043.314786</td>\n",
       "      <td>7539.523630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8013.867190</td>\n",
       "      <td>5038.426608</td>\n",
       "      <td>5354.034205</td>\n",
       "      <td>7676.583535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7384.642239</td>\n",
       "      <td>4605.740309</td>\n",
       "      <td>4863.122323</td>\n",
       "      <td>5642.714913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5145.266619</td>\n",
       "      <td>4887.584093</td>\n",
       "      <td>4908.325414</td>\n",
       "      <td>7601.922150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7059.243142</td>\n",
       "      <td>5676.407761</td>\n",
       "      <td>4917.941055</td>\n",
       "      <td>7361.134909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5400.183210</td>\n",
       "      <td>3124.215440</td>\n",
       "      <td>3452.334999</td>\n",
       "      <td>5856.814860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5044.417326</td>\n",
       "      <td>5841.753952</td>\n",
       "      <td>4835.638414</td>\n",
       "      <td>8770.958591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5695.059209</td>\n",
       "      <td>4015.383782</td>\n",
       "      <td>4833.273373</td>\n",
       "      <td>6083.203203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gamma            v          tau            s\n",
       "0   8884.732608  5092.459921  4542.970058  6707.750088\n",
       "1   4704.557958  5203.909878  5159.123768  7375.008337\n",
       "2   5217.056885  5508.815879  4920.184063  7225.073549\n",
       "3   7011.748107  5988.528729  5294.835363  8611.396447\n",
       "4   6035.102977  4393.755200  4749.595096  6736.258010\n",
       "5   8677.182441  4251.019052  4336.435955  6421.818550\n",
       "6   7369.234961  4864.578853  5164.778288  6552.589846\n",
       "7   7334.908527  4190.840833  4172.384118  6528.635877\n",
       "8   6030.395855  4141.106323  4473.043016  5296.626783\n",
       "9   8099.383958  5314.817037  5415.240393  6434.156664\n",
       "10  7244.654160  3632.125448  3374.219857  5889.242901\n",
       "11  6556.733510  4288.296396  4868.352670  7486.754945\n",
       "12  7477.498633  5665.777880  5440.708012  7546.222567\n",
       "13  7170.113679  4191.561947  4367.144170  7163.378770\n",
       "14  6485.407376  3717.380929  3882.242308  6775.033931\n",
       "15  6425.877406  4660.450008  4707.634304  6721.199446\n",
       "16  6185.433614  5271.489492  5654.610884  6828.246178\n",
       "17  8894.067953  5356.878475  5117.243664  7430.084047\n",
       "18  5250.676408  4487.761192  4419.580821  6799.648448\n",
       "19  3015.906157  2919.125506  3131.643094  4268.952393\n",
       "20  4972.372561  4762.635583  5464.755507  6646.304055\n",
       "21  5278.034575  3950.053569  4071.672884  4820.922179\n",
       "22  7743.988474  4114.612787  3875.449768  6123.320301\n",
       "23  6231.467890  5041.165349  6043.314786  7539.523630\n",
       "24  8013.867190  5038.426608  5354.034205  7676.583535\n",
       "25  7384.642239  4605.740309  4863.122323  5642.714913\n",
       "26  5145.266619  4887.584093  4908.325414  7601.922150\n",
       "27  7059.243142  5676.407761  4917.941055  7361.134909\n",
       "28  5400.183210  3124.215440  3452.334999  5856.814860\n",
       "29  5044.417326  5841.753952  4835.638414  8770.958591\n",
       "30  5695.059209  4015.383782  4833.273373  6083.203203"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 16\n",
      "Percentage of Divergent 0.8\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataFF2018_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataFF2018_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "           Estimate       SE\n",
       "-elpd_waic 16352.35     0.00\n",
       "p_waic        69.68        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 16352.346484198764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "-elpd_loo 16329.65     0.00\n",
       "p_loo        46.99        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_FF2018_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "waic() got an unexpected keyword argument 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d710ea4088ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Note: DIC computation does not work for ADVI fitted models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# But we are using WAIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Found old DIC scores in \"results/waic\". Skipping WAIC computation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_FF2018/glam/models.py\u001b[0m in \u001b[0;36mcompute_waic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             self.waic = np.array([pm.waic(trace=trace, model=model)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: waic() got an unexpected keyword argument 'trace'"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_FF2018_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_FF2018_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_FF2018_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAIC_r(WAIC=32704.32728053088, WAIC_se=0.0, p_WAIC=66.66452633644445, var_warn=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/pymc3/stats.py:292: UserWarning: Estimated shape parameter of Pareto distribution is\n",
      "        greater than 0.7 for one or more samples.\n",
      "        You should consider using a more robust model, this is because\n",
      "        importance sampling is less likely to work well if the marginal\n",
      "        posterior and LOO posterior are very different. This is more likely to\n",
      "        happen with a non-robust model and highly influential observations.\n",
      "  happen with a non-robust model and highly influential observations.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_FF2018_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOO_r(LOO=32653.366046821335, LOO_se=0.0, p_LOO=41.183909481671435, shape_warn=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set data using full GLAM...\n",
      "Replaced attached data (1860 trials) with new data (1860 trials)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>repeat</th>\n",
       "      <th>rt</th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2779.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choice  repeat      rt  subject  trial  item_value_0    gaze_0  \\\n",
       "0     0.0     0.0  3360.0      0.0    0.0           2.0  0.762332   \n",
       "1     0.0     1.0  1598.0      0.0    0.0           2.0  0.762332   \n",
       "2     0.0     2.0  2172.0      0.0    0.0           2.0  0.762332   \n",
       "3     0.0     3.0  2779.0      0.0    0.0           2.0  0.762332   \n",
       "4     0.0     4.0  1360.0      0.0    0.0           2.0  0.762332   \n",
       "\n",
       "   item_value_1    gaze_1  \n",
       "0           1.7  0.237668  \n",
       "1           1.7  0.237668  \n",
       "2           1.7  0.237668  \n",
       "3           1.7  0.237668  \n",
       "4           1.7  0.237668  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_FF2018_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_FF2018_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_FF2018_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting no-bias GLAM hierarchically...\n",
      "Generating hierarchical model for 31 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, v, v_sd, v_mu]\n",
      "Sampling 2 chains:   0%|          | 0/6000 [00:00<?, ?draws/s]/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 2 chains: 100%|██████████| 6000/6000 [5:10:06<00:00,  2.14s/draws]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_FF2018_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_FF2018_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>b</th>\n",
       "      <th>gamma</th>\n",
       "      <th>p_error</th>\n",
       "      <th>s</th>\n",
       "      <th>t0</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.66</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.76</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.13</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413.19</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.02</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>496.86</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.38</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>129.34</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>136.84</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140.92</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146.59</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>180.92</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>313.61</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>146.47</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101.96</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>135.76</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>129.82</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>97.52</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>146.95</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>48.93</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>174.33</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>186.06</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>185.44</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>187.38</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>218.98</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.95</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127.81</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17.67</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>169.61</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>159.06</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>161.58</td>\n",
       "      <td>144.07</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNR  SNR_mu  SNR_sd    b  gamma  p_error         s   t0   tau  tau_mu  \\\n",
       "0   177.66  144.07    31.4  1.0    1.0     0.05  0.007513  0.0  2.77    1.29   \n",
       "1   127.76  144.07    31.4  1.0    1.0     0.05  0.010208  0.0  2.07    1.29   \n",
       "2   155.13  144.07    31.4  1.0    1.0     0.05  0.009075  0.0  1.95    1.29   \n",
       "3   413.19  144.07    31.4  1.0    1.0     0.05  0.006931  0.0  1.80    1.29   \n",
       "4    91.02  144.07    31.4  1.0    1.0     0.05  0.007725  0.0  3.32    1.29   \n",
       "5   496.86  144.07    31.4  1.0    1.0     0.05  0.007489  0.0  1.32    1.29   \n",
       "6   105.38  144.07    31.4  1.0    1.0     0.05  0.009102  0.0  3.40    1.29   \n",
       "7   129.34  144.07    31.4  1.0    1.0     0.05  0.006906  0.0  1.28    1.29   \n",
       "8   136.84  144.07    31.4  1.0    1.0     0.05  0.008900  0.0  0.10    1.29   \n",
       "9   140.92  144.07    31.4  1.0    1.0     0.05  0.007791  0.0  3.19    1.29   \n",
       "10  146.59  144.07    31.4  1.0    1.0     0.05  0.007975  0.0  0.52    1.29   \n",
       "11  180.92  144.07    31.4  1.0    1.0     0.05  0.008096  0.0  2.65    1.29   \n",
       "12  313.61  144.07    31.4  1.0    1.0     0.05  0.008442  0.0  1.51    1.29   \n",
       "13  146.47  144.07    31.4  1.0    1.0     0.05  0.008012  0.0  1.80    1.29   \n",
       "14  101.96  144.07    31.4  1.0    1.0     0.05  0.005415  0.0  2.27    1.29   \n",
       "15  135.76  144.07    31.4  1.0    1.0     0.05  0.007838  0.0  0.89    1.29   \n",
       "16  129.82  144.07    31.4  1.0    1.0     0.05  0.007864  0.0  1.36    1.29   \n",
       "17   97.52  144.07    31.4  1.0    1.0     0.05  0.006869  0.0  0.32    1.29   \n",
       "18  146.95  144.07    31.4  1.0    1.0     0.05  0.008268  0.0  0.30    1.29   \n",
       "19   48.93  144.07    31.4  1.0    1.0     0.05  0.004935  0.0  0.34    1.29   \n",
       "20  174.33  144.07    31.4  1.0    1.0     0.05  0.007782  0.0  3.21    1.29   \n",
       "21  186.06  144.07    31.4  1.0    1.0     0.05  0.006724  0.0  0.21    1.29   \n",
       "22  185.44  144.07    31.4  1.0    1.0     0.05  0.009099  0.0  2.03    1.29   \n",
       "23  187.38  144.07    31.4  1.0    1.0     0.05  0.007851  0.0  0.51    1.29   \n",
       "24  218.98  144.07    31.4  1.0    1.0     0.05  0.007317  0.0  1.88    1.29   \n",
       "25  148.95  144.07    31.4  1.0    1.0     0.05  0.008325  0.0  1.39    1.29   \n",
       "26  127.81  144.07    31.4  1.0    1.0     0.05  0.007924  0.0  0.16    1.29   \n",
       "27   17.67  144.07    31.4  1.0    1.0     0.05  0.009511  0.0  0.29    1.29   \n",
       "28  169.61  144.07    31.4  1.0    1.0     0.05  0.006413  0.0  0.79    1.29   \n",
       "29  159.06  144.07    31.4  1.0    1.0     0.05  0.008503  0.0  0.45    1.29   \n",
       "30  161.58  144.07    31.4  1.0    1.0     0.05  0.007733  0.0  0.30    1.29   \n",
       "\n",
       "    tau_sd         v      v_mu      v_sd  \n",
       "0     0.76  0.000048  0.000058  0.000015  \n",
       "1     0.76  0.000039  0.000058  0.000015  \n",
       "2     0.76  0.000057  0.000058  0.000015  \n",
       "3     0.76  0.000050  0.000058  0.000015  \n",
       "4     0.76  0.000090  0.000058  0.000015  \n",
       "5     0.76  0.000032  0.000058  0.000015  \n",
       "6     0.76  0.000086  0.000058  0.000015  \n",
       "7     0.76  0.000048  0.000058  0.000015  \n",
       "8     0.76  0.000062  0.000058  0.000015  \n",
       "9     0.76  0.000044  0.000058  0.000015  \n",
       "10    0.76  0.000053  0.000058  0.000015  \n",
       "11    0.76  0.000056  0.000058  0.000015  \n",
       "12    0.76  0.000036  0.000058  0.000015  \n",
       "13    0.76  0.000047  0.000058  0.000015  \n",
       "14    0.76  0.000051  0.000058  0.000015  \n",
       "15    0.76  0.000057  0.000058  0.000015  \n",
       "16    0.76  0.000063  0.000058  0.000015  \n",
       "17    0.76  0.000070  0.000058  0.000015  \n",
       "18    0.76  0.000056  0.000058  0.000015  \n",
       "19    0.76  0.000106  0.000058  0.000015  \n",
       "20    0.76  0.000045  0.000058  0.000015  \n",
       "21    0.76  0.000036  0.000058  0.000015  \n",
       "22    0.76  0.000072  0.000058  0.000015  \n",
       "23    0.76  0.000043  0.000058  0.000015  \n",
       "24    0.76  0.000035  0.000058  0.000015  \n",
       "25    0.76  0.000048  0.000058  0.000015  \n",
       "26    0.76  0.000059  0.000058  0.000015  \n",
       "27    0.76  0.000059  0.000058  0.000015  \n",
       "28    0.76  0.000038  0.000058  0.000015  \n",
       "29    0.76  0.000055  0.000058  0.000015  \n",
       "30    0.76  0.000046  0.000058  0.000015  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_FF2018_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>b</th>\n",
       "      <th>gamma</th>\n",
       "      <th>p_error</th>\n",
       "      <th>s</th>\n",
       "      <th>t0</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.63</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.41</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.55</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.06</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.26</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.54</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>215.37</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202.01</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>161.54</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167.26</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>145.86</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>146.76</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>142.95</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>153.58</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>142.90</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156.47</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153.80</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>116.37</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.62</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51.37</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>170.17</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>233.57</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>122.64</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>158.13</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>229.97</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>191.97</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>149.48</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>245.22</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>206.94</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>144.36</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>271.19</td>\n",
       "      <td>144.5</td>\n",
       "      <td>57.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNR  SNR_mu  SNR_sd    b  gamma  p_error         s   t0   tau  tau_mu  \\\n",
       "0   168.63   144.5   57.82  1.0    1.0     0.05  0.007958  0.0  2.65    0.95   \n",
       "1   122.41   144.5   57.82  1.0    1.0     0.05  0.010110  0.0  1.78    0.95   \n",
       "2   151.55   144.5   57.82  1.0    1.0     0.05  0.008478  0.0  1.75    0.95   \n",
       "3   136.06   144.5   57.82  1.0    1.0     0.05  0.006783  0.0  1.11    0.95   \n",
       "4    79.26   144.5   57.82  1.0    1.0     0.05  0.007077  0.0  2.43    0.95   \n",
       "5   112.54   144.5   57.82  1.0    1.0     0.05  0.007223  0.0  1.58    0.95   \n",
       "6   215.37   144.5   57.82  1.0    1.0     0.05  0.011701  0.0  1.09    0.95   \n",
       "7   202.01   144.5   57.82  1.0    1.0     0.05  0.007848  0.0  1.25    0.95   \n",
       "8   161.54   144.5   57.82  1.0    1.0     0.05  0.009143  0.0  0.02    0.95   \n",
       "9   167.26   144.5   57.82  1.0    1.0     0.05  0.008773  0.0  1.47    0.95   \n",
       "10  145.86   144.5   57.82  1.0    1.0     0.05  0.006973  0.0  0.71    0.95   \n",
       "11  146.76   144.5   57.82  1.0    1.0     0.05  0.007493  0.0  0.41    0.95   \n",
       "12  142.95   144.5   57.82  1.0    1.0     0.05  0.007887  0.0  1.19    0.95   \n",
       "13  153.58   144.5   57.82  1.0    1.0     0.05  0.007044  0.0  1.39    0.95   \n",
       "14  142.90   144.5   57.82  1.0    1.0     0.05  0.006693  0.0  1.89    0.95   \n",
       "15  156.47   144.5   57.82  1.0    1.0     0.05  0.008742  0.0  1.54    0.95   \n",
       "16  153.80   144.5   57.82  1.0    1.0     0.05  0.008450  0.0  3.17    0.95   \n",
       "17  116.37   144.5   57.82  1.0    1.0     0.05  0.006639  0.0  1.39    0.95   \n",
       "18   95.62   144.5   57.82  1.0    1.0     0.05  0.006102  0.0  0.03    0.95   \n",
       "19   51.37   144.5   57.82  1.0    1.0     0.05  0.004361  0.0  0.16    0.95   \n",
       "20  170.17   144.5   57.82  1.0    1.0     0.05  0.008133  0.0  0.79    0.95   \n",
       "21  233.57   144.5   57.82  1.0    1.0     0.05  0.007873  0.0  0.96    0.95   \n",
       "22  122.64   144.5   57.82  1.0    1.0     0.05  0.009591  0.0  1.97    0.95   \n",
       "23  158.13   144.5   57.82  1.0    1.0     0.05  0.008661  0.0  0.68    0.95   \n",
       "24  229.97   144.5   57.82  1.0    1.0     0.05  0.007356  0.0  4.47    0.95   \n",
       "25  191.97   144.5   57.82  1.0    1.0     0.05  0.008214  0.0  1.24    0.95   \n",
       "26  149.48   144.5   57.82  1.0    1.0     0.05  0.009180  0.0  0.12    0.95   \n",
       "27  245.22   144.5   57.82  1.0    1.0     0.05  0.011570  0.0  0.93    0.95   \n",
       "28  206.94   144.5   57.82  1.0    1.0     0.05  0.007285  0.0  0.80    0.95   \n",
       "29  144.36   144.5   57.82  1.0    1.0     0.05  0.008070  0.0  0.66    0.95   \n",
       "30  271.19   144.5   57.82  1.0    1.0     0.05  0.007688  0.0  0.24    0.95   \n",
       "\n",
       "    tau_sd         v     v_mu      v_sd  \n",
       "0     0.94  0.000051  0.00006  0.000014  \n",
       "1     0.94  0.000082  0.00006  0.000014  \n",
       "2     0.94  0.000056  0.00006  0.000014  \n",
       "3     0.94  0.000050  0.00006  0.000014  \n",
       "4     0.94  0.000090  0.00006  0.000014  \n",
       "5     0.94  0.000064  0.00006  0.000014  \n",
       "6     0.94  0.000080  0.00006  0.000014  \n",
       "7     0.94  0.000046  0.00006  0.000014  \n",
       "8     0.94  0.000057  0.00006  0.000014  \n",
       "9     0.94  0.000050  0.00006  0.000014  \n",
       "10    0.94  0.000048  0.00006  0.000014  \n",
       "11    0.94  0.000051  0.00006  0.000014  \n",
       "12    0.94  0.000055  0.00006  0.000014  \n",
       "13    0.94  0.000046  0.00006  0.000014  \n",
       "14    0.94  0.000047  0.00006  0.000014  \n",
       "15    0.94  0.000056  0.00006  0.000014  \n",
       "16    0.94  0.000063  0.00006  0.000014  \n",
       "17    0.94  0.000057  0.00006  0.000014  \n",
       "18    0.94  0.000064  0.00006  0.000014  \n",
       "19    0.94  0.000101  0.00006  0.000014  \n",
       "20    0.94  0.000048  0.00006  0.000014  \n",
       "21    0.94  0.000034  0.00006  0.000014  \n",
       "22    0.94  0.000078  0.00006  0.000014  \n",
       "23    0.94  0.000054  0.00006  0.000014  \n",
       "24    0.94  0.000031  0.00006  0.000014  \n",
       "25    0.94  0.000057  0.00006  0.000014  \n",
       "26    0.94  0.000061  0.00006  0.000014  \n",
       "27    0.94  0.000059  0.00006  0.000014  \n",
       "28    0.94  0.000035  0.00006  0.000014  \n",
       "29    0.94  0.000053  0.00006  0.000014  \n",
       "30    0.94  0.000037  0.00006  0.000014  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/pymc3/stats.py:292: UserWarning: Estimated shape parameter of Pareto distribution is\n",
      "        greater than 0.7 for one or more samples.\n",
      "        You should consider using a more robust model, this is because\n",
      "        importance sampling is less likely to work well if the marginal\n",
      "        posterior and LOO posterior are very different. This is more likely to\n",
      "        happen with a non-robust model and highly influential observations.\n",
      "  happen with a non-robust model and highly influential observations.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_FF2018_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set data using no-bias GLAM...\n",
      "Replaced attached data (1860 trials) with new data (1860 trials)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>repeat</th>\n",
       "      <th>rt</th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3097.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choice  repeat      rt  subject  trial  item_value_0    gaze_0  \\\n",
       "0     0.0     0.0  4306.0      0.0    0.0           2.0  0.762332   \n",
       "1     0.0     1.0  1850.0      0.0    0.0           2.0  0.762332   \n",
       "2     0.0     2.0  2673.0      0.0    0.0           2.0  0.762332   \n",
       "3     0.0     3.0  3377.0      0.0    0.0           2.0  0.762332   \n",
       "4     0.0     4.0  3097.0      0.0    0.0           2.0  0.762332   \n",
       "\n",
       "   item_value_1    gaze_1  \n",
       "0           1.7  0.237668  \n",
       "1           1.7  0.237668  \n",
       "2           1.7  0.237668  \n",
       "3           1.7  0.237668  \n",
       "4           1.7  0.237668  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_FF2018_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_FF2018_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_FF2018_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close Figure to continue...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'glam_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aacf88876c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Close Figure to continue...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mglam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglam_nobias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glam_full' is not defined"
     ]
    }
   ],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates.item(0)\n",
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa = glam_nobias.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims =(0, 10)\n",
    "\n",
    "# Compute relevant variables\n",
    "df = glam.plots.add_difficulty(testa)\n",
    "\n",
    "# Compute summary statistics\n",
    "subject_means = df.groupby(['subject', 'difficulty']).rt.mean()\n",
    "means = subject_means.groupby('difficulty').mean()[xlims[0]:xlims[1]]\n",
    "sems = subject_means.groupby('difficulty').sem()[xlims[0]:xlims[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
